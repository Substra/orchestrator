# Default values for orchestrator.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

## @section Global orchestrator settings
## @param imagePullSecrets Image pull secrets
##
imagePullSecrets: []
## @param nameOverride String to partially override the `orchestrator.fullname`
##
nameOverride: ""
## @param fullnameOverride String to fully override the `orchestrator.fullname`
##
fullnameOverride: ""


serviceAccount:
  ## @param serviceAccount.create Enable creation of a ServiceAccount for the orchestrator pods
  ##
  create: true
  ## @param serviceAccount.annotations Annotations to add to the ServiceAccount
  ##
  annotations: {}
  ## @param serviceAccount.name Name of the created ServiceAccount
  ## If not set and create is true, a name is generated using the fullname template
  ##
  name: ""

## @param podAnnotations Orchestrator pod annotations
##
podAnnotations: {}

## @param podSecurityContext Orchestrator pod security context
##
podSecurityContext: {}
  # fsGroup: 2000

## @param securityContext Orchestrator container security context
##
securityContext: {}
  # capabilities:
  #   drop:
  #   - ALL
  # readOnlyRootFilesystem: true
  # runAsNonRoot: true
  # runAsUser: 1000


service:
  ## @param service.type Orchestrator service type
  ##
  type: ClusterIP
  ## @param service.port Orchestrator service port
  ##
  port: 9000
  ## @param service.nodePort Orchestrator service port on the node if service type is `NodePort`
  ##
  nodePort: ""


metrics:
  ## @param metrics.enabled Expose Prometheus metrics
  ##
  enabled: false

  serviceMonitor:
    ## @param metrics.serviceMonitor.enabled Create ServiceMonitor resource for scraping metrics using Prometheus Operator
    ##
    enabled: false
    ## @param metrics.serviceMonitor.namespace Namespace for the ServiceMonitor resource (defaults to the Release Namespace)
    ##
    namespace: ""
    ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped
    ##
    interval: ""
    ## @param metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended
    ##
    scrapeTimeout: ""
    ## @param metrics.serviceMonitor.relabelings RelabelConfigs to apply to samples before scraping
    ##
    relabelings: []
    ## @param metrics.serviceMonitor.metricRelabelings MetricRelabelConfigs to apply to samples before insertion
    ##
    metricRelabelings: []
    ## @param metrics.serviceMonitor.honorLabels Specify honorLabels parameter of the scrape endpoint
    ##
    honorLabels: false


ingress:
  ## @param ingress.enabled Enable ingress for Orchestrator service
  ##
  enabled: false
  ## @param ingress.ingressClassName Ingress class name
  ##
  ingressClassName:
  ## @skip ingress.annotations
  annotations:
    nginx.ingress.kubernetes.io/ssl-passthrough: "true"
  ## @param ingress.path path of the deault host
  ##
  path: /
  ## @param ingress.hostname hostname of the default host
  hostname: ""
  ## @param ingress.extraPaths The list of extra paths to be created for the default host
  ## e.g:
  ## extraPaths:
  ##   - path: /
  ##     pathType: ImplementationSpecific
  ##     backend:
  ##       service:
  ##         name: orchestrator-backend-svc
  ##         port:
  ##           name: http
  ##
  extraPaths: []
  ## @param ingress.pathType Ingress path type
  ##
  pathType: ImplementationSpecific
  ## @param ingress.extraHosts The list of additional hostnames to be covered with this ingress record
  ## e.g:
  ## extraHosts:
  ##   - name: chart-example.local
  ##     path: /
  ##     pathType: ImplementationSpecific
  ##
  extraHosts: []
  ## @param ingress.extraTls The tls configuration for hostnames to be coverred by the ingress
  ## e.g:
  ## extraTls:
  ##   - hosts:
  ##       - chart-example.local
  ##     secretName: connect-tls
  ##
  extraTls: []


resources:
  requests:
    ## @param resources.requests.cpu CPU request for the `orchestrator` container
    cpu: 500m
    ## @param resources.requests.memory memory request for the `orchestrator` container
    memory: 200Mi
  limits:
    ## @param resources.limits.cpu CPU limits for the `orchestrator` container
    cpu: 500m
    ## @param resources.limits.memory memory limit for the `orchestrator` container
    memory: 800Mi

## @param nodeSelector Node labels used for pod assignment
##
nodeSelector: {}

## @param tolerations Tolerations labels for pod assignment
##
tolerations: []

## @param affinity Affinity settings for pod assignment
##
affinity: {}

## @section Database connection settings
database:
  auth:
    ## @param database.auth.database what DB to connect to
    database: &psql-database orchestrator
    ## @param database.auth.username what user to connect as
    username: &psql-username postgres
    ## @param database.auth.password what password to use for connecting
    password: &psql-password postgres

    ## @param database.auth.credentialsSecretName An alternative to giving username and password; must have `DATABASE_USERNAME` and `DATABASE_PASSWORD` keys.
    ##
    credentialsSecretName: null

  ## @param database.host Hostname of the database to connect to (defaults to local)
  host: null
  ## @param database.port Port of an external database to connect to
  port: 5432

  ## @param database.connectionParameters database URI parameters (`key=value&key=value`)
  ## (https://www.postgresql.org/docs/15/libpq-connect.html#LIBPQ-CONNSTRING)
  ## if using the integrated PostgreSQL and this is empty, it is set to `sslmode=disable`
  connectionParameters: ""

## @section PostgreSQL settings
## @descriptionStart
## Database included as a subchart used by default.
##
## See Bitnami documentation: https://bitnami.com/stack/postgresql/helm
## @descriptionEnd
postgresql:
  ## @param postgresql.enabled Deploy a PostgreSQL instance along the orchestrator for its use
  ##
  enabled: true
  ## @skip postgresql.auth
  auth:
    enablePostgresUser: false
    username: *psql-username
    password: *psql-password
    database: *psql-database
  ## @skip postgresql.primary
  primary:
    extendedConfiguration: |-
      tcp_keepalives_idle = 5
    podSecurityContext:
      runAsNonRoot: true
      runAsUser: 1001
      fsGroup: 1001
      seccompProfile:
        type: RuntimeDefault
    containerSecurityContext:
      allowPrivilegeEscalation: false
      capabilities:
        drop:
        - ALL
    resources:
      requests:
        memory: 512Mi
        cpu: 1000m
      limits:
        memory: 2Gi
        cpu: 1000m

# grpcOptions:
#   keepalive:
#     timeMs: 120000
#   maxSendMessageLength: -1
#   maxReceiveMessageLength: -1
#   keepaliveTimeoutMs: 20000
#   http2MaxPingsWithoutData: 0
#   keepalivePermitWithoutCalls: 1


## @section Orchestrator application specific parameters
##
orchestrator:
  image:
    ## @param orchestrator.image.registry `orchestrator` image repository
    ##
    registry: ghcr.io
    ## @param orchestrator.image.repository `orchestrator` image repository
    ##
    repository: substra/orchestrator-server
    ## @param orchestrator.image.pullPolicy `orchestrator` image pull policy
    ##
    pullPolicy: IfNotPresent
    ## @param orchestrator.image.tag `orchestrator` image tag (defaults to AppVersion)
    ##
    tag: null

  ## @param orchestrator.fullnameOverride String to fully override the `orchestrator.server.fullname`
  ##
  fullnameOverride: ""
  ## @param orchestrator.logLevel Orchestrator log level
  ##
  logLevel: INFO
  ## @param orchestrator.logSQLVerbose Log SQL statements with debug verbosity
  ##
  logSQLVerbose: false
  ## @param orchestrator.verifyClientMSPID If true, validates incoming gRPC requests by checking the `mspid` header matches the subject organization of the client SSL certificate. See [MSPID check](#MSPID-check)
  ##
  verifyClientMSPID: false
  ## @param orchestrator.txRetryBudget Duration ([go format](https://golang.org/pkg/time/#ParseDuration)) during which the transaction can be retried in case of conflicting writes
  ##
  txRetryBudget: 500ms

  tls:
    createCertificates:
      ## @param orchestrator.tls.createCertificates.enabled If true creates a cert-manager _Certificate_ resource for the Orchestrator
      ##
      enabled: false
      ## @param orchestrator.tls.createCertificates.domains A list of domains to be covered by the generated certificate
      ##
      domains: []
      ## @param orchestrator.tls.createCertificates.duration TTL of the Orchestrator certificate
      ## Default 90 days
      ##
      duration: 2160h
      ## @param orchestrator.tls.createCertificates.issuer _Issuer_ or _ClusterIssuer_ responsible for the creation of this _Certificate_
      ##
      issuer: ""
      ## @param orchestrator.tls.createCertificates.issuerKind Certificate issuer kind (`Issuer` or `ClusterIssuer`)
      ##
      issuerKind: ClusterIssuer
    ## @param orchestrator.tls.enabled If true, enable TLS for the orchestrator gRPC endpoint
    ##
    enabled: false
    ## @param orchestrator.tls.secrets.pair A secret containing the server TLS cert/key pair `tls.crt` and `tls.key`
    ##
    secrets:
      pair: orchestrator-tls-server-pair
    ## @param orchestrator.tls.cacert A ConfigMap containing the server TLS CA cert `cat.crt`
    ##
    cacert: orchestrator-tls-cacert
    mtls:
      ## @param orchestrator.tls.mtls.enabled If true, enable TLS client verification
      ##
      enabled: false
      ## @param orchestrator.tls.mtls.clientCACerts A map whose keys are names of the CAs, and values are a list of configmaps containing CA certificates
      ## Here you should provide the orchestrator clients ca certs if you are using a private certificate authority
      ## e.g:
      ## orchestrator-ca:
      ##   - orchestrator-tls-cacert
      ##
      clientCACerts: {}

## @section Channels settings
## @param channels List of channels and their members (MSPID)
## e.g:
##  - name: mychannel
##    organizations: [ MyOrg1MSP, MyOrg2MSP ]
##  - name: yourchannel
##    organizations: [ MyOrg1MSP, MyOrg2MSP ]
##
channels: []


## @section migration job settings
migrations:
  ## @param migrations.fullnameOverride String to fully override the `migrations.server.fullname`
  ##
  fullnameOverride: ""

## @section Images
##
initImages:
  initPostgresql:
    ## @param initImages.initPostgresql.repository PostgreSQL image
    ## @param initImages.initPostgresql.tag PostgreSQL tag
    ## @param initImages.initPostgresql.registry The registry to pull the PostgreSQL image
    registry: docker.io
    repository: postgres
    tag: 17